# demo.py
import cv2
import torch
import numpy as np
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
from insectid.detector import YOLOv5Detector
from insectid.idfinder import MobileNetClassifier

class PestAnalysisPipeline:
    def __init__(self, 
                 detector_weights: str,
                 classifier_weights: str,
                 detection_conf: float = 0.3,
                 classify_conf: float = 0.5,
                 device: str = 'auto',
                 insid_map_path: str = 'insectid/kiteluo_insid_map.txt',
                 font_path: str = 'PingFang Regular.ttf'):
        """
        :param detector_weights: YOLOv5æ£€æµ‹æ¨¡å‹è·¯å¾„
        :param classifier_weights: MobileNetåˆ†ç±»æ¨¡å‹è·¯å¾„
        :param detection_conf: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
        :param classify_conf: åˆ†ç±»ç»“æœç½®ä¿¡åº¦é˜ˆå€¼
        :param device: è¿è¡Œè®¾å¤‡ (auto/cpu/cuda)
        :param insid_map_path: ç‰©ç§ä¿¡æ¯æ˜ å°„æ–‡ä»¶è·¯å¾„
        :param font_path: ä¸­æ–‡å­—ä½“æ–‡ä»¶è·¯å¾„
        """
        # è®¾å¤‡ç»Ÿä¸€å¤„ç†
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨å’Œåˆ†ç±»å™¨
        self.detector = YOLOv5Detector(
            weights_path=detector_weights, 
            conf_thres=detection_conf,
            device=self.device
        )
        self.classifier = MobileNetClassifier(
            model_weights=classifier_weights,
            device=self.device
        )
        
        # åŠ è½½æ˜ å°„è¡¨
        self.insid_map = self._load_insid_map(insid_map_path)
        
        # åŠ è½½å­—ä½“æ–‡ä»¶ï¼ˆå…³é”®ä¿®å¤ï¼‰
        self.font = None
        font_path = Path(font_path)
        if font_path.exists():
            try:
                self.font = ImageFont.truetype(str(font_path), 20)
                print(f"âœ… å­—ä½“åŠ è½½æˆåŠŸ: {font_path}")
            except Exception as e:
                print(f"â€¼ï¸ å­—ä½“åŠ è½½å¤±è´¥: {str(e)}")
                self.font = ImageFont.load_default()
        else:
            print(f"âš ï¸ å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {font_path}")
            self.font = ImageFont.load_default()
        
        # åˆå§‹åŒ–é˜ˆå€¼å‚æ•°ï¼ˆå…³é”®ä¿®å¤ï¼‰
        self.classify_conf = classify_conf  # å­˜å‚¨åŸå§‹é…ç½®å€¼
        self.classify_conf_thres = classify_conf
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        print("\n=== é…ç½®ä¿¡æ¯ ===")
        print(f"æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼: {detection_conf}")
        print(f"åˆ†ç±»ç½®ä¿¡åº¦é˜ˆå€¼: {classify_conf}")
        print(f"è®¾å¤‡: {self.device}")
        print("===============\n")

    def _load_insid_map(self, path: str) -> dict:
        """è§£æç‰©ç§ä¿¡æ¯æ˜ å°„æ–‡ä»¶"""
        insid_map = {}
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                if ',' in line:
                    chinese_part, sci_part = line.split(',', 1)
                    sci_name = sci_part.split('#')[0].strip().replace(' ', '_')
                    insid_map[sci_name] = {
                        'chinese': chinese_part.strip(),
                        'scientific': sci_part.split('#')[0].strip()
                    }
        return insid_map

    def _merge_boxes(self, detections, iou_threshold=0.5):
        """æ”¹è¿›çš„NMSåˆå¹¶æ–¹æ³•"""
        if not detections:
            return []
        if len(detections) == 1:
            return detections  # å•æ¡†ç›´æ¥ä¿ç•™

        # åæ ‡è½¬æ¢
        boxes = [
            [det['bbox'][0], det['bbox'][1], 
             det['bbox'][2]-det['bbox'][0], 
             det['bbox'][3]-det['bbox'][1]] 
            for det in detections
        ]
        scores = [det['conf'] for det in detections]

        # æ‰§è¡ŒNMS
        indices = cv2.dnn.NMSBoxes(
            boxes, scores, 
            score_threshold=0.01, 
            nms_threshold=iou_threshold
        )
        return [detections[i] for i in indices] if indices else []

    def _crop_and_resize(self, img, bbox):
        """ä¼˜åŒ–è£å‰ªé€»è¾‘"""
        x1, y1, x2, y2 = [max(0, int(v)) for v in bbox]
        crop = img[y1:y2, x1:x2]
        if crop.size == 0:
            return None
        
        # ä¿æŒé•¿å®½æ¯”ç¼©æ”¾
        h, w = crop.shape[:2]
        scale = 224 / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        resized = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)
        
        # å±…ä¸­å¡«å……
        canvas = np.zeros((224, 224, 3), dtype=np.uint8)
        dx, dy = (224 - new_w) // 2, (224 - new_h) // 2
        canvas[dy:dy+new_h, dx:dx+new_w] = resized
        return canvas

    def process_image(self, img_path: str, output_dir: str = None):
        """æ ¸å¿ƒå¤„ç†æµç¨‹"""
        img = cv2.imread(img_path)
        if img is None:
            raise FileNotFoundError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")

        # æ£€æµ‹é˜¶æ®µ
        raw_detections = self.detector.detect(img)
        print(f"[æ£€æµ‹] åŸå§‹æ¡†æ•°é‡: {len(raw_detections)}")

        # åˆå¹¶é˜¶æ®µ
        detections = self._merge_boxes(raw_detections)
        print(f"[NMS] æœ‰æ•ˆæ¡†æ•°é‡: {len(detections)}")

        results = []
        for idx, det in enumerate(detections):
            crop_img = self._crop_and_resize(img, det['bbox'])
            if crop_img is None:
                continue

            try:
                # åˆ†ç±»é˜¶æ®µ
                cls_result = self.classifier.classify(crop_img)
                print(f"[åˆ†ç±»] ç»“æœ: {cls_result['class_name']} ç½®ä¿¡åº¦: {cls_result['confidence']:.2f}")

                # ç½®ä¿¡åº¦è¿‡æ»¤
                if cls_result['confidence'] < self.classify_conf_thres:
                    print(f"ğŸš« è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ ({cls_result['confidence']:.2f} < {self.classify_conf_thres})")
                    continue

                # æ˜ å°„æ ¡éªŒ
                map_info = self.insid_map.get(
                    cls_result['class_name'],
                    {'chinese': 'æœªçŸ¥ç‰©ç§', 'scientific': 'Unknown'}
                )
                results.append({
                    'bbox': det['bbox'],
                    'conf': cls_result['confidence'],
                    'chinese': map_info['chinese'],
                    'scientific': map_info['scientific']
                })

            except Exception as e:
                print(f"â€¼ï¸ åˆ†ç±»å¤±è´¥: {str(e)}")
                continue

        # å¯è§†åŒ–ä¸ä¿å­˜
        vis_img = self._draw_chinese(img, results)
        if output_dir:
            output_path = Path(output_dir) / f"result_{Path(img_path).name}"
            cv2.imwrite(str(output_path), vis_img)
            print(f"âœ… ç»“æœä¿å­˜: {output_path}")

        return vis_img, results

    def _draw_chinese(self, image, results):
        """å…¼å®¹æ€§å¯è§†åŒ–æ–¹æ³•"""
        try:
            if not results:
                return image

            img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)

            for result in results:
                x1, y1, x2, y2 = result['bbox']
                label = f"{result['chinese']} {result['scientific']} {result['conf']:.2f}"

                # è®¡ç®—æ–‡æœ¬å°ºå¯¸
                if hasattr(self.font, 'getbbox'):
                    bbox = self.font.getbbox(label)
                    text_width = bbox[2] - bbox[0]
                    text_height = bbox[3] - bbox[1]
                else:
                    text_width, text_height = self.font.getsize(label)

                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                draw.rectangle(
                    [x1, y1-text_height-5, x1+text_width+10, y1],
                    fill=(0, 150, 0)
                )
                
                # ç»˜åˆ¶æ–‡æœ¬
                draw.text(
                    (x1+5, y1-text_height-2),
                    label,
                    font=self.font,
                    fill=(255, 255, 255)
                )

                # ç»˜åˆ¶è¾¹æ¡†
                draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0), width=2)

            return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        except Exception as e:
            print(f"â€¼ï¸ å¯è§†åŒ–é”™è¯¯: {str(e)}")
            return image

if __name__ == "__main__":
    # ================= é…ç½®å‚æ•° =================
    CONFIG = {
        "input_path": "æ”¹å†™ä¸ºä½ çš„å›¾ç‰‡è·¯å¾„",
        "output_dir": "æ”¹å†™ä¸ºè¯†åˆ«åçš„ç›®æ ‡è·¯å¾„",
        "detector_weights": "YOLOv5çš„æƒé‡è·¯å¾„",
        "classifier_weights": "MobileNetV3çš„æƒé‡è·¯å¾„",
        "detection_conf": 0.3,
        "classify_conf": 0.5,
        "font_path": "å­—ä½“è·¯å¾„"  # ç»å¯¹è·¯å¾„
    }

    # ================= åˆå§‹åŒ–æµæ°´çº¿ =================
    pipeline = PestAnalysisPipeline(
        detector_weights=CONFIG["detector_weights"],
        classifier_weights=CONFIG["classifier_weights"],
        detection_conf=CONFIG["detection_conf"],
        classify_conf=CONFIG["classify_conf"],
        font_path=CONFIG["font_path"]
    )

    # ================= å¤„ç†è¾“å…¥ =================
    input_path = Path(CONFIG["input_path"])
    output_dir = Path(CONFIG["output_dir"])
    output_dir.mkdir(parents=True, exist_ok=True)

    if input_path.is_file():
        print(f"å¤„ç†æ–‡ä»¶: {input_path}")
        pipeline.process_image(str(input_path), str(output_dir))
    elif input_path.is_dir():
        print(f"æ‰¹é‡å¤„ç†ç›®å½•: {input_path}")
        for img_file in input_path.glob('*.[jJ][pP][gG]'):  # æ”¯æŒå¤§å°å†™
            print(f"å¤„ç†: {img_file.name}")
            pipeline.process_image(str(img_file), str(output_dir))

    print(f"âœ… å¤„ç†å®Œæˆï¼ç»“æœç›®å½•: {output_dir.resolve()}")